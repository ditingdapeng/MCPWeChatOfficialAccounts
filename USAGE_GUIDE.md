# MCPå¾®ä¿¡çˆ¬è™«ä½¿ç”¨æŒ‡å—

## ğŸš¨ å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

### é—®é¢˜1: "Could not find file 'weixin_articles/xxx.txt'"

**åŸå› ï¼š** æ™ºèƒ½ä½“åœ¨é”™è¯¯çš„è·¯å¾„æŸ¥æ‰¾æ–‡ä»¶

**è§£å†³æ–¹æ¡ˆï¼š**
1. **ç¡®è®¤æ–‡ä»¶ä¿å­˜ä½ç½®**ï¼šæ–‡ç« å®é™…ä¿å­˜åœ¨ `articles/` ç›®å½•
2. **ä½¿ç”¨æ­£ç¡®çš„MCPé…ç½®**ï¼šå‚è€ƒ `mcp_config.json`
3. **æ™ºèƒ½ä½“é…ç½®**ï¼šç¡®ä¿æ™ºèƒ½ä½“ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„æ˜ å°„

```bash
# æ£€æŸ¥æ–‡ç« æ˜¯å¦å­˜åœ¨
ls -la articles/

# æŸ¥çœ‹æœ€è¿‘çˆ¬å–çš„æ–‡ç« 
ls -la articles/*/
```

### é—®é¢˜2: "Missing required parameter 'article_data'"

**åŸå› ï¼š** ç›´æ¥è°ƒç”¨åˆ†æå·¥å…·è€Œæ²¡æœ‰å…ˆçˆ¬å–æ–‡ç« æ•°æ®

**è§£å†³æ–¹æ¡ˆï¼š**
1. **æ­£ç¡®çš„è°ƒç”¨é¡ºåº**ï¼š
   ```
   1. å…ˆè°ƒç”¨ crawl_weixin_article çˆ¬å–æ–‡ç« 
   2. å†è°ƒç”¨ analyze_article_content åˆ†ææ–‡ç« 
   ```

2. **ç¤ºä¾‹å·¥ä½œæµç¨‹**ï¼š
   ```json
   // æ­¥éª¤1: çˆ¬å–æ–‡ç« 
   {
     "tool": "crawl_weixin_article",
     "parameters": {
       "url": "https://mp.weixin.qq.com/s/KJl2oTMaKRra2l0PV7IIiA",
       "download_images": true
     }
   }
   
   // æ­¥éª¤2: åˆ†ææ–‡ç« ï¼ˆä½¿ç”¨æ­¥éª¤1è¿”å›çš„article_dataï¼‰
   {
     "tool": "analyze_article_content",
     "parameters": {
       "article_data": "<ä»æ­¥éª¤1è·å–çš„æ–‡ç« æ•°æ®>",
       "analysis_type": "full"
     }
   }
   ```

### é—®é¢˜3: "download_images: false" ä½†æœŸæœ›ä¸‹è½½å›¾ç‰‡

**åŸå› ï¼š** æ™ºèƒ½ä½“ä¼ é€’äº†é”™è¯¯çš„å‚æ•°å€¼

**è§£å†³æ–¹æ¡ˆï¼š**
1. **æ£€æŸ¥æ™ºèƒ½ä½“é…ç½®**ï¼šç¡®ä¿ä½¿ç”¨é»˜è®¤å‚æ•°
2. **æ˜ç¡®æŒ‡å®šå‚æ•°**ï¼š
   ```json
   {
     "url": "https://mp.weixin.qq.com/s/KJl2oTMaKRra2l0PV7IIiA",
     "download_images": true  // æ˜ç¡®è®¾ç½®ä¸ºtrue
   }
   ```

## ğŸ”§ MCPæœåŠ¡å™¨é…ç½®

### 1. ç¯å¢ƒå˜é‡é…ç½®

```bash
# è®¾ç½®æ–‡ç« ä¿å­˜ç›®å½•
export ARTICLES_DIR="articles"

# è®¾ç½®é»˜è®¤ä¸‹è½½å›¾ç‰‡
export DOWNLOAD_IMAGES="true"

# è®¾ç½®æ— å¤´æ¨¡å¼
export HEADLESS="true"
```

### 2. æ™ºèƒ½ä½“é…ç½®æ–‡ä»¶

ä½¿ç”¨æä¾›çš„ `mcp_config.json` é…ç½®æ–‡ä»¶ï¼š

```json
{
  "mcp_servers": {
    "weixin_spider": {
      "command": "python",
      "args": ["src/mcp_weixin_spider/server.py"],
      "env": {
        "ARTICLES_DIR": "articles",
        "DOWNLOAD_IMAGES": "true"
      }
    }
  },
  "default_parameters": {
    "crawl_weixin_article": {
      "download_images": true
    }
  }
}
```

## ğŸ“‹ æ­£ç¡®çš„ä½¿ç”¨æµç¨‹

### 1. å¯åŠ¨MCPæœåŠ¡å™¨

```bash
cd MCPWeiXin
python src/mcp_weixin_spider/server.py
```

### 2. çˆ¬å–æ–‡ç« 

```python
# ä½¿ç”¨Pythonå®¢æˆ·ç«¯
import asyncio
from mcp_weixin_spider.client import WeixinSpiderClient

async def main():
    client = WeixinSpiderClient()
    await client.connect("src/mcp_weixin_spider/server.py")
    
    # çˆ¬å–æ–‡ç« ï¼ˆé»˜è®¤ä¸‹è½½å›¾ç‰‡ï¼‰
    result = await client.crawl_article(
        "https://mp.weixin.qq.com/s/KJl2oTMaKRra2l0PV7IIiA",
        download_images=True
    )
    
    print("çˆ¬å–ç»“æœ:", result)
    
    # åˆ†ææ–‡ç« 
    if "article" in result:
        analysis = await client.analyze_article(
            result["article"], 
            analysis_type="full"
        )
        print("åˆ†æç»“æœ:", analysis)
    
    await client.disconnect()

asyncio.run(main())
```

### 3. æŸ¥çœ‹çˆ¬å–çš„æ–‡ç« 

```python
# æŸ¥çœ‹æœ€è¿‘æ–‡ç« 
recent = await client.read_resource("weixin://articles/recent")
print("æœ€è¿‘æ–‡ç« :", recent)

# æŸ¥çœ‹é…ç½®
config = await client.read_resource("weixin://config/spider")
print("é…ç½®ä¿¡æ¯:", config)
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### 1. æ£€æŸ¥æ–‡ä»¶è·¯å¾„

```bash
# æ£€æŸ¥å½“å‰ç›®å½•ç»“æ„
tree articles/ -L 2

# æˆ–è€…ä½¿ç”¨ls
find articles/ -name "*.json" -o -name "*.txt" | head -10
```

### 2. æ£€æŸ¥MCPæœåŠ¡å™¨æ—¥å¿—

```bash
# å¯åŠ¨æœåŠ¡å™¨æ—¶æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
DEBUG=1 python src/mcp_weixin_spider/server.py
```

### 3. éªŒè¯å‚æ•°

```python
# æµ‹è¯•å‚æ•°éªŒè¯
from mcp_weixin_spider.server import validate_crawl_parameters

try:
    params = validate_crawl_parameters({
        "url": "https://mp.weixin.qq.com/s/test",
        "download_images": True
    })
    print("å‚æ•°éªŒè¯é€šè¿‡:", params)
except ValueError as e:
    print("å‚æ•°é”™è¯¯:", e)
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡çˆ¬å–å¤šç¯‡æ–‡ç« 
urls = [
    "https://mp.weixin.qq.com/s/url1",
    "https://mp.weixin.qq.com/s/url2",
    "https://mp.weixin.qq.com/s/url3"
]

for i, url in enumerate(urls):
    result = await client.crawl_article(url, custom_filename=f"article_{i+1}")
    print(f"å®Œæˆç¬¬{i+1}ç¯‡æ–‡ç« ")
    
    # æ·»åŠ å»¶æ—¶é¿å…è¢«é™åˆ¶
    await asyncio.sleep(2)
```

### 2. é€‰æ‹©æ€§ä¸‹è½½å›¾ç‰‡

```python
# åªçˆ¬å–æ–‡æœ¬ï¼Œä¸ä¸‹è½½å›¾ç‰‡ï¼ˆæé«˜é€Ÿåº¦ï¼‰
result = await client.crawl_article(url, download_images=False)

# åç»­éœ€è¦æ—¶å†ä¸‹è½½å›¾ç‰‡
if need_images:
    result_with_images = await client.crawl_article(url, download_images=True)
```

### 3. è‡ªå®šä¹‰æ–‡ä»¶å

```python
# ä½¿ç”¨è‡ªå®šä¹‰æ–‡ä»¶åé¿å…é‡å¤
from datetime import datetime

custom_name = f"article_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
result = await client.crawl_article(url, custom_filename=custom_name)
```

## ğŸ” è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### 2. æ£€æŸ¥è¿”å›æ•°æ®ç»“æ„

```python
import json

result = await client.crawl_article(url)
print(json.dumps(result, ensure_ascii=False, indent=2))
```

### 3. éªŒè¯æ–‡ç« æ•°æ®å®Œæ•´æ€§

```python
def check_article_data(article_data):
    required_fields = ["title", "author", "content", "url"]
    missing = [f for f in required_fields if f not in article_data]
    if missing:
        print(f"ç¼ºå°‘å­—æ®µ: {missing}")
    else:
        print("æ–‡ç« æ•°æ®å®Œæ•´")
    
    print(f"å†…å®¹é•¿åº¦: {len(article_data.get('content', ''))} å­—ç¬¦")
    print(f"å›¾ç‰‡æ•°é‡: {len(article_data.get('images', []))} å¼ ")
```

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°å…¶ä»–é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶**ï¼šæ£€æŸ¥è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
2. **æ£€æŸ¥ç½‘ç»œè¿æ¥**ï¼šç¡®ä¿èƒ½è®¿é—®å¾®ä¿¡å…¬ä¼—å·æ–‡ç« 
3. **éªŒè¯URLæ ¼å¼**ï¼šç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å¾®ä¿¡æ–‡ç« é“¾æ¥
4. **æ›´æ–°ä¾èµ–**ï¼šç¡®ä¿æ‰€æœ‰PythonåŒ…éƒ½æ˜¯æœ€æ–°ç‰ˆæœ¬

```bash
# æ›´æ–°ä¾èµ–
pip install -U selenium beautifulsoup4 requests webdriver-manager Pillow
```